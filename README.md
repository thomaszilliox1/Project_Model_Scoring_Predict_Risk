## Project Model Scoring and MLOps Deployment

This project showcases the complete lifecycle of a machine learning model â€” from development and version control to deployment and production monitoring. It emphasizes MLOps best practices to ensure scalability, maintainability, and continuous performance tracking of models.

Key Skills Acquired : 

    - Model Lifecycle Management: Managing versioning, tracking, and storage of models using MLflow.

    - Cloud Deployment: Designing and deploying models in the cloud through automated CI/CD pipelines.

    - API Development: Creating and deploying prediction APIs with frameworks such as FastAPI or Flask.

    - Model Monitoring: Continuously tracking model performance, detecting data drift, and ensuring long-term reliability.

    - Testing & Automation: Implementing unit tests and automating deployment workflows with GitHub Actions.


Technologies Used : 

    - MLflow: Tracking, versioning, and serving models through the model registry.

    - Git & GitHub: Managing code versioning and collaboration, with continuous integration powered by GitHub Actions.

    - FastAPI / Flask: Developing and deploying RESTful APIs for real-time model inference.

    - Pytest / Unittest: Automating unit tests to ensure the reliability of the prediction API.

    - GitHub Actions: Implementing CI/CD pipelines for automated cloud deployment.

    - Heroku: Hosting and deploying machine learning models in the cloud environment.
